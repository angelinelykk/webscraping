{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import re \n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 1: from name to google search\n",
    "def getGoogleSearchURL(company_name, website):\n",
    "    split_name = company_name.lower().split()\n",
    "    URL = 'https://www.google.com/search?q='\n",
    "    for piece in split_name:\n",
    "        URL += piece\n",
    "        URL += '+'\n",
    "    URL += website\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 2: from google search to websiteURL\n",
    "def getURL(googleSearch, website, company_name):\n",
    "    name = company_name.split()[0].lower()\n",
    "    page = requests.get(googleSearch)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    print(soup)\n",
    "    result_div = soup.find_all('div', attrs = {'class': 'ZINbbc'})\n",
    "    links = []\n",
    "    for r in result_div:\n",
    "        try:\n",
    "            link = r.find('a', href = True)\n",
    "            if link != '':\n",
    "                links.append(link['href'])\n",
    "        except:\n",
    "            continue\n",
    "    clean_links = []\n",
    "    for link in links:\n",
    "        clean = re.search('\\/url\\?q\\=(.*)\\&sa', link)\n",
    "        if clean is None:\n",
    "            continue\n",
    "        clean_links.append(clean.group(1))\n",
    "    final = None\n",
    "    for link in clean_links:\n",
    "        if website == 'sgpgrid' and 'https://sgpgrid.com/company-details/' in link and name in link:\n",
    "            final = link\n",
    "        if website == 'linkedin' and 'https://sg.linkedin.com/company/' in link and name in link:\n",
    "            final = link\n",
    "        if website == 'crunchbase' and 'https://www.crunchbase.com/organization/' in link and name in link:\n",
    "            final = link\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html PUBLIC \"-//W3C//DTD HTML 4.01 Transitional//EN\">\n",
      "\n",
      "<html>\n",
      "<head><meta content=\"text/html; charset=utf-8\" http-equiv=\"content-type\"/><meta content=\"initial-scale=1\" name=\"viewport\"/><title>https://www.google.com/search?q=facebook+linkedin</title></head>\n",
      "<body onload=\"e=document.getElementById('captcha');if(e){e.focus();}\" style=\"font-family: arial, sans-serif; background-color: #fff; color: #000; padding:20px; font-size:18px;\">\n",
      "<div style=\"max-width:400px;\">\n",
      "<hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/><br/>\n",
      "<form action=\"index\" id=\"captcha-form\" method=\"post\">\n",
      "<script async=\"\" defer=\"\" src=\"https://www.google.com/recaptcha/api.js\"></script>\n",
      "<script>var submitCallback = function(response) {document.getElementById('captcha-form').submit();};</script>\n",
      "<div class=\"g-recaptcha\" data-callback=\"submitCallback\" data-s=\"neLgLFAaDbizfiw7DuCDgniG6207_wjRjQdXdUqWKF9Z8cGqzB6h7fIDFPhqtw4zkdyKwRN2F92jxaD-zcew-kNiaUJ21P0mCzZ4We9jAvw7zHSDA3v_ekUBqbgdfPikG1NQOSyUaKLGgKqukTlRdG3NXQZ4Ucih06oOWoNhB34Vs4RTH4x3aKjEfGuSmDu-gjJ-R91suIvnB-DDeliQT05WeRYz0x_AfoS34aU\" data-sitekey=\"6LfwuyUTAAAAAOAmoS0fdqijC2PbbdH4kjq62Y1b\" id=\"recaptcha\"></div>\n",
      "<input name=\"q\" type=\"hidden\" value=\"EgRvQUSwGNCfy4YGIhBjbbRAyqYH1n4sOsawAM4oMgFy\"/><input name=\"continue\" type=\"hidden\" value=\"https://www.google.com/search?q=facebook+linkedin\"/>\n",
      "</form>\n",
      "<hr noshade=\"\" size=\"1\" style=\"color:#ccc; background-color:#ccc;\"/>\n",
      "<div style=\"font-size:13px;\">\n",
      "<b>About this page</b><br/><br/>\n",
      "\n",
      "Our systems have detected unusual traffic from your computer network.  This page checks to see if it's really you sending the requests, and not a robot.  <a href=\"#\" onclick=\"document.getElementById('infoDiv').style.display='block';\">Why did this happen?</a><br/><br/>\n",
      "<div id=\"infoDiv\" style=\"display:none; background-color:#eee; padding:10px; margin:0 0 15px 0; line-height:1.4em;\">\n",
      "This page appears when Google automatically detects requests coming from your computer network which appear to be in violation of the <a href=\"//www.google.com/policies/terms/\">Terms of Service</a>. The block will expire shortly after those requests stop.  In the meantime, solving the above CAPTCHA will let you continue to use our services.<br/><br/>This traffic may have been sent by malicious software, a browser plug-in, or a script that sends automated requests.  If you share your network connection, ask your administrator for help â€” a different computer using the same IP address may be responsible.  <a href=\"//support.google.com/websearch/answer/86640\">Learn more</a><br/><br/>Sometimes you may be asked to solve the CAPTCHA if you are using advanced terms that robots are known to use, or sending requests very quickly.\n",
      "</div>\n",
      "\n",
      "IP address: 111.65.68.176<br/>Time: 2021-06-23T06:08:17Z<br/>URL: https://www.google.com/search?q=facebook+linkedin<br/>\n",
      "</div>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n",
      "https://www.google.com/search?q=facebook+linkedin\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "googleSearch = getGoogleSearchURL('facebook', 'linkedin')\n",
    "URL = getURL(googleSearch, 'linkedin', 'facebook')\n",
    "print(googleSearch)\n",
    "print(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#crunchbase\n",
    "def getCrunchbaseURL(company_name):\n",
    "    googleURL = getGoogleSearchURL(company_name, 'crunchbase')\n",
    "    URL = getURL(googleURL, 'crunchbase', company_name)\n",
    "    if URL == None:\n",
    "        URL = 'No information available'\n",
    "    return URL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3: from sgpgrid URL to company details\n",
    "def getGridSingleCompanyDetails(URL):\n",
    "    if URL == None:\n",
    "        return ['No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information', 'No information']\n",
    "    page = requests.get(URL)\n",
    "    soup = BeautifulSoup(page.content, 'html.parser')\n",
    "    data = json.loads(soup.find(\"script\", type = \"application/json\").string)\n",
    "    manpower = data['props']['initialState']['singleCompany']['company']['numberOfStaff']\n",
    "    manpower_global = data['props']['initialState']['singleCompany']['company']['numberOfStaffGlobal']\n",
    "    total_capital = data['props']['initialState']['singleCompany']['company']['totalCapital']\n",
    "    PUC_ordinary = data['props']['initialState']['singleCompany']['company']['paidupCapitalOrdinaryShares'][0]\n",
    "    PUC_preference = data['props']['initialState']['singleCompany']['company']['paidupCapitalPreferenceShares'][0]\n",
    "    PUC_others = data['props']['initialState']['singleCompany']['company']['paidUpCapitalOthersShares'][0]\n",
    "    business_activity = data['props']['initialState']['singleCompany']['company']['businessActivity']\n",
    "    primary_described_activity = data['props']['initialState']['singleCompany']['company']['primaryDescribedActivity']\n",
    "    secondary_described_activity = data['props']['initialState']['singleCompany']['company']['secondaryDescribedActivity']\n",
    "    website = data['props']['initialState']['singleCompany']['company']['url']\n",
    "    primarySSIC = data['props']['initialState']['singleCompany']['company']['primarySsicDescription']\n",
    "    secondarySSIC = data['props']['initialState']['singleCompany']['company']['secondarySsicDescription']\n",
    "    details = [manpower, manpower_global, total_capital, PUC_ordinary, PUC_preference, PUC_others, business_activity, primary_described_activity, secondary_described_activity, website, primarySSIC, secondarySSIC]\n",
    "    for index in range(len(details)):\n",
    "        if details[index] == None:\n",
    "            details[index] = 'No information'      \n",
    "    return details\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 4: print company details\n",
    "def printSingleCompany(detailsList):\n",
    "    websites = ['sgpgrid']\n",
    "    index = 0\n",
    "    for details in detailsList:\n",
    "        print(websites[index])\n",
    "        print('')\n",
    "        index += 1\n",
    "        if details == None:\n",
    "            print(\"No information available\")\n",
    "            return None\n",
    "        print('Manpower: ', details[0])\n",
    "        print('Manpower Global: ', details[1])\n",
    "        print('Total Capital: ', details[2])\n",
    "        print('Paid-up capital(Ordinary shares): ', details[3]['currency'], details[3]['ordinary'])\n",
    "        print('Paid-up capital(Preference shares): ', details[4]['currency'], details[4]['preference'])\n",
    "        print('Paid-up capital(Other shares): ', details[5]['currency'], details[5]['others'])\n",
    "        print('Business Activity: ', details[6])\n",
    "        print('Primary Described Activity: ', details[7])\n",
    "        print('Secondary Described Activity: ', details[8])\n",
    "        print('Website: ', details[9])\n",
    "        print('______________________________________________________')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#From company name to information\n",
    "def getInfo(company_name):\n",
    "    links = []\n",
    "    googleSearchGrid = getGoogleSearchURL(company_name, 'sgpgrid')\n",
    "    gridURL = getURL(googleSearchGrid, 'sgpgrid', company_name)\n",
    "    gridDetails = getGridSingleCompanyDetails(gridURL)\n",
    "    return [gridDetails]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up linkedin opening\n",
    "from selenium import webdriver\n",
    "\n",
    "driver = webdriver.Chrome(\"/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/chromedriver_binary/chromedriver\")\n",
    "driver.get('https://www.linkedin.com/login?trk=guest_homepage-basic_nav-header-signin')\n",
    "username = driver.find_element_by_id('username')\n",
    "username.send_keys('angelinelyk@berkeley.edu')\n",
    "password = driver.find_element_by_id('password')\n",
    "password.send_keys('gea8pjma')\n",
    "sign_in_button = driver.find_element_by_xpath('//*[@type=\"submit\"]')\n",
    "sign_in_button.click()\n",
    "\n",
    "driver.get('https://www.linkedin.com/company/twitter/?originalSubdomain=sg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Consolidation for linked in\n",
    "def getLinkedInDetails(company_name):\n",
    "    googleURL = getGoogleSearchURL(company_name, 'linkedin')\n",
    "    linkedinURL = getURL(googleURL, 'linkedin', company_name)\n",
    "    if linkedinURL == None:\n",
    "        return ['No information', 'No information', 'No information', 'No information']\n",
    "    details = getSingleLinkedInDetails(linkedinURL)\n",
    "    return details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consolidation\n",
    "def getSingleLinkedInDetails(URL):\n",
    "    print(URL)\n",
    "    getLinkedIn(URL)\n",
    "    about = getAboutPage()\n",
    "    getLinkedIn(about)\n",
    "    details = getAboutDetails()\n",
    "    details.append(URL)\n",
    "    return details  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getLinkedIn(URL):\n",
    "    driver.get(URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAboutPage():\n",
    "    links = driver.find_elements_by_xpath(\"//a[@href]\")\n",
    "    while len(links):\n",
    "        url = links.pop()\n",
    "        url = url.get_attribute(\"href\")\n",
    "        if '/about/' in url:\n",
    "            return url\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAboutDetails():\n",
    "    main = driver.find_element_by_id('main')\n",
    "    mb6 = main.find_element_by_class_name('mb6')\n",
    "    description = mb6.find_element_by_tag_name('p')\n",
    "    website = mb6.find_element_by_tag_name('span')\n",
    "    dd = mb6.find_elements_by_tag_name('dd')\n",
    "    employees = getEmployees(dd)\n",
    "    return [description.text, website.text, employees]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getEmployees(descriptions):\n",
    "    employees = None\n",
    "    while len(descriptions):\n",
    "        small = descriptions.pop()\n",
    "        if 'employees' in small.text:\n",
    "            employees = small.text\n",
    "            employees = employees.split()\n",
    "            employees = employees[0]\n",
    "    return employees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "362\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "test = pd.read_csv('/Users/angelinelee/Documents/webscraping/test1.csv')\n",
    "test_df = pd.DataFrame(test)\n",
    "test_df['Web Presence'] = None\n",
    "test_df['Company Background'] = None\n",
    "test_df['LinkedIn-description'] = None\n",
    "test_df['Grid-business activity'] = None\n",
    "test_df['Grid-primary activity'] = None\n",
    "test_df['Grid-primary SSIC description'] = None\n",
    "test_df['Grid-secondary activity'] = None\n",
    "test_df['Grid-secondary SSIC description'] = None\n",
    "test_df['Has any of the C-suite exited before?'] = None\n",
    "test_df['LinkedIn Links'] = None\n",
    "test_df['Subsector'] = None\n",
    "test_df['Specific subsector'] = None\n",
    "test_df['Manpower'] = None\n",
    "test_df['LinkedIn-manpower'] = None\n",
    "test_df['Grid-manpower'] = None\n",
    "test_df['Grid-manpower global'] = None\n",
    "test_df['Level of funding'] = None\n",
    "test_df['Total Funding'] = None\n",
    "test_df['Grid-total capital'] = None\n",
    "test_df['Grid-PUC(ordinary)'] = None\n",
    "test_df['Grid-PUC(preference)'] = None\n",
    "test_df['Grid-PUC(others)'] = None\n",
    "test_df['Crunchbase Link'] = None\n",
    "test_df['Company Website'] = None\n",
    "test_df['LinkedIn-website'] = None\n",
    "test_df['Grid-website'] = None\n",
    "#test_df.loc[0, 'Grid-manpower'] = 2\n",
    "print(test_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "previous_name = None\n",
    "unique_companies = 0\n",
    "for index in range(test_df.shape[0]): \n",
    "    name = test_df.iloc[index]['Companies'].lower()\n",
    "    if name != previous_name:\n",
    "        n = random.randint(0,45)\n",
    "        time.sleep(n)\n",
    "        unique_companies += 1\n",
    "        detailsGrid = getInfo(name)\n",
    "        test_df.loc[index]['Grid-manpower'] = detailsGrid[0][0]\n",
    "        test_df.loc[index]['Grid-manpower global'] = detailsGrid[0][1]\n",
    "        test_df.loc[index]['Grid-total capital'] = detailsGrid[0][2]\n",
    "        if detailsGrid[0][3] == 'No information':\n",
    "            test_df.loc[index]['Grid-PUC(ordinary)'] = 'No information'\n",
    "        if detailsGrid[0][3] != 'No information':\n",
    "            if detailsGrid[0][3]['ordinary'] != None:\n",
    "                test_df.loc[index]['Grid-PUC(ordinary)'] = detailsGrid[0][3]['currency'] + ' ' + detailsGrid[0][3]['ordinary']\n",
    "            if detailsGrid[0][3]['ordinary'] == None:\n",
    "                test_df.loc[index]['Grid-PUC(ordinary)'] = 'No information'\n",
    "        if detailsGrid[0][4] == 'No information':\n",
    "            test_df.loc[index]['Grid-PUC(preference)'] = 'No information'\n",
    "        if detailsGrid[0][4] != 'No information':\n",
    "            if detailsGrid[0][4]['preference'] != None:\n",
    "                test_df.loc[index]['Grid-PUC(preference)'] = detailsGrid[0][4]['currency'] + ' ' + detailsGrid[0][4]['preference']\n",
    "            if detailsGrid[0][4]['preference'] == None:\n",
    "                test_df.loc[index]['Grid-PUC(preference)'] = 'No information'\n",
    "        if detailsGrid[0][5] == 'No information':\n",
    "            test_df.loc[index]['Grid-PUC(others)'] = 'No information'\n",
    "        if detailsGrid[0][5] != 'No information':\n",
    "            if detailsGrid[0][5]['others'] != None:\n",
    "                test_df.loc[index]['Grid-PUC(others)'] = detailsGrid[0][5]['currency'] + ' ' + detailsGrid[0][5]['others']\n",
    "            if detailsGrid[0][5]['others'] == None:\n",
    "                test_df.loc[index]['Grid-PUC(others)'] = 'No information'\n",
    "        test_df.loc[index]['Grid-business activity'] = detailsGrid[0][6]\n",
    "        test_df.loc[index]['Grid-primary activity'] = detailsGrid[0][7]\n",
    "        test_df.loc[index]['Grid-secondary activity'] = detailsGrid[0][8]\n",
    "        test_df.loc[index]['Grid-website'] = detailsGrid[0][9]\n",
    "        test_df.loc[index]['Grid-primary SSIC description'] = detailsGrid[0][10]\n",
    "        test_df.loc[index]['Grid-secondary SSIC description'] = detailsGrid[0][11]\n",
    "        \n",
    "        detailsLinkedIn = getLinkedInDetails(name)\n",
    "        test_df.loc[index]['LinkedIn-manpower'] = detailsLinkedIn[2]\n",
    "        test_df.loc[index]['LinkedIn-description'] = detailsLinkedIn[0]\n",
    "        test_df.loc[index]['LinkedIn-website'] = detailsLinkedIn[1]\n",
    "        test_df.loc[index]['LinkedIn Links'] = detailsLinkedIn[3]\n",
    "        \n",
    "        test_df.loc[index]['Crunchbase Link'] = getCrunchbaseURL(name)\n",
    "        print(unique_companies)\n",
    "    previous_name = name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataframe to excel sheet\n",
    "test_df.to_excel('/Users/angelinelee/Documents/webscraping/exporttest4.xlsx', index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
